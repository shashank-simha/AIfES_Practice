{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0fbadd-8c64-4bf2-9ac4-7f7f7ff1e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d2d0c4-f75c-4a22-a46f-b8a71377f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee77554-b067-468b-8b48-d1e55adcb85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data:\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "test_data:\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(f'training_data:\\n{train_data}')\n",
    "print(f'test_data:\\n{test_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5af130-b3a1-49a0-b889-67cac71a438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data data shape: torch.Size([60000, 28, 28])\n",
      "training_data targets shape: torch.Size([60000])\n",
      "test_data data shape: torch.Size([10000, 28, 28])\n",
      "test_data targets shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'training_data data shape: {train_data.data.shape}')\n",
    "print(f'training_data targets shape: {train_data.targets.shape}')\n",
    "print(f'test_data data shape: {test_data.data.shape}')\n",
    "print(f'test_data targets shape: {test_data.targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cb4014-f007-417c-b38f-927e5490c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "\n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size=100,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d8f0d5-dfb9-446c-987b-832340ee97ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x72fcd02455e0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x72fcd029e390>}\n"
     ]
    }
   ],
   "source": [
    "print(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39beaa2e-9b4c-42e9-bb8c-14ccc0ff5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d04dfd-7f58-4410-9d80-488230d6dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743cf13a-a231-40a5-bbfb-ddce45e4f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct /len(loaders[\"test\"].dataset):.0f}%\\f)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49fe32a0-16d1-4665-9696-f36e5acdd07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78732/599564851.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.302471\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.293704\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.167045\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.013592\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.921172\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.813292\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.773293\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.756521\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.779469\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.731945\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.722484\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.697890\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.688562\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.671321\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.701394\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.644233\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.605002\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.714235\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.633261\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.607833\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.639500\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.573329\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.652787\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.621736\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.615734\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.600566\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.624295\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.590575\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.631584\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.660356\n",
      "Test set: Average loss: 0.0153, Accuracy 9339/10000 (93%\f",
      ")\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.598127\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.596677\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.639719\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.601286\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.547833\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.557694\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.605495\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.579590\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.579514\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.638747\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.581863\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.618110\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.544522\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.601693\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.570112\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.598636\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.595901\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.617074\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.519141\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.524018\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.552430\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.563282\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.536665\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.576751\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.583864\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.650628\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.518906\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.533911\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.559525\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.578470\n",
      "Test set: Average loss: 0.0151, Accuracy 9500/10000 (95%\f",
      ")\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.593470\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.564116\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.557861\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.509766\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.590170\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.578327\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.606627\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.527543\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.570828\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.534595\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.583681\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.580631\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.528298\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.536144\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.530820\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.550804\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.522184\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.556674\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.615430\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.599761\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.607906\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.578345\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.563234\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.591359\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.581648\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.527424\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.523447\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.527899\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.568227\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.594451\n",
      "Test set: Average loss: 0.0150, Accuracy 9601/10000 (96%\f",
      ")\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.573264\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.515098\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.523311\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.520427\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.554335\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.560558\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.527706\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.565078\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.584427\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.544136\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.535468\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.567899\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.550003\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.594050\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.527864\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.539254\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.519279\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.600981\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.550411\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.515944\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.507286\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.590473\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.538517\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.575402\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.574516\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.539533\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.579091\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.582021\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.543593\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.540468\n",
      "Test set: Average loss: 0.0150, Accuracy 9639/10000 (96%\f",
      ")\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.500715\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.536568\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.561701\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.522031\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.538513\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.537726\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.552259\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.496202\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.548578\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.539393\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.541567\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.571848\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.541156\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.564219\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.528874\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.532637\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.508767\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.590574\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.570351\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.541012\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.560490\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.552323\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.513341\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.510953\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.532013\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.563313\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.537035\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.531181\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.508691\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.563605\n",
      "Test set: Average loss: 0.0149, Accuracy 9671/10000 (97%\f",
      ")\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.554978\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.502697\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.563000\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.536826\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.550438\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.553428\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.541680\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.563974\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.553855\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.582405\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.543517\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.552362\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.552068\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.522237\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.541651\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.550561\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.498654\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.530691\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.575490\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.573410\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.531613\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.500295\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.508101\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.558990\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.534820\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.533073\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.550638\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.515254\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.546472\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.502331\n",
      "Test set: Average loss: 0.0149, Accuracy 9690/10000 (97%\f",
      ")\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.522321\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.508797\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.534681\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.537980\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.546481\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.544927\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.547689\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.478353\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.536269\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.523889\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.514672\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.525922\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.538160\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.538711\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.534136\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.527125\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.532865\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.500856\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.531508\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.516901\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.516445\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.526554\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.525724\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.536639\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.528456\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.563383\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.520393\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.519645\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.520315\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.561069\n",
      "Test set: Average loss: 0.0149, Accuracy 9684/10000 (97%\f",
      ")\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.508745\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.558580\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.533152\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.546582\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.505425\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.526312\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.549910\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.543427\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.504303\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.522956\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.557528\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.536798\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.502033\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.553466\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.513939\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.561102\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.547781\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.580920\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.532228\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.552728\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.539141\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.513860\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.493240\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.550513\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.522050\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.546205\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.489620\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.541508\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.528266\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.514910\n",
      "Test set: Average loss: 0.0149, Accuracy 9717/10000 (97%\f",
      ")\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.532000\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.537430\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.540112\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.531054\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.547732\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.518107\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.561584\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.516999\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.504251\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.495821\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.492440\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.518833\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.537237\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.518336\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.555042\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.504597\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.553252\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.515318\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.522582\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.548873\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.548322\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.478644\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.567984\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.511319\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.508139\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.508371\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.510235\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.542956\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.534733\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.519752\n",
      "Test set: Average loss: 0.0149, Accuracy 9745/10000 (97%\f",
      ")\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.521586\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.498416\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.515349\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.506612\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.527601\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.546035\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.521147\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.528784\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.487608\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.513531\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.559651\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.524499\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.495236\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.565339\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.515616\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.522997\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.517845\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.521532\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.550497\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.527671\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.504782\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.570658\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.578781\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.473602\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.526052\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.479262\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.520037\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.563945\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.520625\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.549382\n",
      "Test set: Average loss: 0.0149, Accuracy 9737/10000 (97%\f",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61e2272-95c0-4210-9b9b-802913261e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78732/599564851.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[10]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3709c498-a340-4bb9-9527-39f60b67da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da14d2-6840-4508-8ed9-f402f0795c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
